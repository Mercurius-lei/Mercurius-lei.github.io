{"posts":[{"title":"MySQL","text":"","link":"/2023/09/25/database_mysql/"},{"title":"Elasticsearch","text":"","link":"/2023/09/25/database_elasticsearch/"},{"title":"常用设计模式","text":"1、在超类中加上新的行为，会使得某些并不适合该行为的子类也具有该行为。 因此为了复用而使用继承，并不完美。 设计原则设计原则1找到应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。 设计原则2针对接口编程，而不是针对实现编程。 充分利用多态的特性，变量的声明类型应该是一个超类型，通常是一个抽象类或者是一个接口。","link":"/2023/09/25/design_pattern/"},{"title":"Sql优化","text":"数据库 1、 分库分库 就是将数据库中的数据分散到不同的数据库上，可以垂直分库，也可以水平分库。 垂直分库 就是把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。例如：说你将数据库中的用户表、订单表和商品表分别单独拆分为用户数据库、订单数据库和商品数据库。 水平分库 是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。例如：订单表数据量太大，你对订单表进行了水平切分（水平分表），然后将切分后的 2 张订单表分别放在两个不同的数据库。 ##2、分表 分表 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。 垂直分表 是对数据表列的拆分，把一张列比较多的表拆分为多张表。例如：我们可以将用户信息表中的一些列单独抽出来作为一个表。 水平分表 是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。例如：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 ##3、分库分表场景 单表的数据达到千万级别以上，数据库读写速度比较缓慢。 数据库中的数据占用的空间越来越大，备份时间越来越长。 应用的并发量太大。 ##4、分库分表引入的问题 join 操作 事务问题 分布式 ID 跨库聚合查询问题 …… ##5、分库分表后的数据迁移 （1）停机更新 （2）增量迁移 （3）双写 ##6、MySQL Online DDL MySQL 的 DDL 有很多种方法。 MySQL 本身自带三种方法，分别是：copy、inplace、instant。 copy 算法为最古老的算法，在 MySQL 5.5 及以下为默认算法。MySQL 会建立一个新的临时表，把源表的所有数据写入到临时表，在此期间无法对源表进行数据写入。MySQL 在完成临时表的写入之后，用临时表替换掉源表。这个算法主要被早期（&lt;=5.5）版本所使用。 从 MySQL 5.6 开始，引入了 inplace 算法并且默认使用。inplace 算法还包含两种类型：rebuild-table 和 not-rebuild-table。MySQL 使用 inplace 算法时，会自动判断，能使用 not-rebuild-table 的情况下会尽量使用，不能的时候才会使用 rebuild-table。当 DDL 涉及到主键和全文索引相关的操作时，无法使用 not-rebuild-table，必须使用 rebuild-table。其他情况下都会使用 not-rebuild-table。 nplace 算法的操作阶段主要分为三个： Prepare阶段： - 创建新的临时 frm 文件(与 InnoDB 无关)。 - 持有 EXCLUSIVE-MDL 锁，禁止读写。 - 根据 alter 类型，确定执行方式（copy，online-rebuild，online-not-rebuild）。 更新数据字典的内存对象。 - 分配 row_log 对象记录数据变更的增量（仅 rebuild 类型需要）。 - 生成新的临时ibd文件 new_table（仅rebuild类型需要）。 Execute 阶段： 降级EXCLUSIVE-MDL锁，允许读写。 扫描old_table聚集索引（主键）中的每一条记录 rec。 遍历new_table的聚集索引和二级索引，逐一处理。 根据 rec 构造对应的索引项。 将构造索引项插入 sort_buffer 块排序。 将 sort_buffer 块更新到 new_table 的索引上。 记录 online-ddl 执行过程中产生的增量（仅 rebuild 类型需要）。 重放 row_log 中的操作到 new_table 的索引上（not-rebuild 数据是在原表上更新）。 重放 row_log 中的DML操作到 new_table 的数据行上。 Commit阶段： 当前 Block 为 row_log 最后一个时，禁止读写，升级到 EXCLUSIVE-MDL 锁。 重做 row_log 中最后一部分增量。 更新 innodb 的数据字典表。 提交事务（刷事务的 redo 日志）。 修改统计信息。 rename 临时 ibd 文件，frm文件。 变更完成，释放 EXCLUSIVE-MDL 锁。 从 MySQL 8.0.12 开始，引入了 instant 算法并且默认使用。目前 instant 算法只支持增加列等少量 DDL 类型的操作（可以直接修改表的 metadata 数据，省掉了 rebuild 的过程，极大的缩短了 DDL 语句的执行时间），其他类型仍然会默认使用 inplace。 有一些第三方工具也可以实现 DDL 操作，最常见的是 percona 的 pt-online-schema-change 工具（简称为 pt-osc），和 github 的 gh-ost 工具，均支持 MySQL 5.5 以上的版本。 需要注意以下几个方面： （1）负载 所有方式对大表做 DDL 都会增加负载，只是程度的不同，主要为 IO 的负载。如果是 IO 使用非常高的实例，建议在 IO 较小的时间段执行 DDL 操作。 （2）额外空间占用 copy、inplace rebuild-table、gh-ost、pt-online-schema-change，都会将表完整复制一份出来再做 DDL 变更，因此会使用和原表空间一样大（甚至更大，如果是加列的操作的话）的额外空间，另外还会生成大量的临时日志。要特别注意剩余空间，确保空间充裕，不然可能导致 DDL 过程中磁盘写满。 （3）主从同步延时 所有方式做 DDL 均会引发主从同步延时。其中 copy 和 inplace 算法，只有主完成了 DDL 操作之后，binlog 才会同步给从库，从库才能开始操作 DDL，从库操作完 DDL 之后才能开始操作其他语句，因此会造成巨大的（大概两倍 DDL 操作时间）的延时。其他方法产生的延时较小，但仍然可能有几秒的延时。 （4）MDL 所有方式做 DDL 均会产生 MDL（metadata lock）。除了 copy 模式会有持续性的锁（DDL 的整个过程期间无法向该表写入任何数据）之外，其他方式的 MDL 均为短暂的锁。 除了 copy 模式之外的所有模式，MDL 如下： 在 DDL 的开始阶段，申请该表的 EXCLUSIVE-MDL 锁，禁止读写 降级 EXCLUSIVE-MDL 锁，允许读写 在 DDL 的最终 COMMIT 阶段，升级 EXCLUSIVE-MDL 锁，禁止读写 其中的阶段一和阶段三，其 MDL 的持续时间都是非常短暂的，也就是申请到了 MDL 锁之后会在很快的时间（一般小于一秒）处理完成相关操作并释放锁，一般情况下是不会影响业务的。只有阶段二是真正在处理数据，持续时间一般较长。 但是，有可能出现在阶段一和阶段三，无法申请到 MDL 的情况。这是因为 MDL 和所有的读写语句都可能会产生冲突，如果是在申请 MDL 的时候，之前有读写的事务一直没有执行完成（或者执行完成之后一直没有 COMMIT），MDL 就会无法立刻申请到，这个时候，DDL 语句，以及所有在该 DDL 语句之后的读写事务，都会阻塞并等待之前的读写事务完成，导致整个实例处于不可用状态。这个时候 SHOW PROCESSLIST 看到的语句状态为 waiting for metadata lock。 （5）其他 MySQL 的 inplace 算法虽然支持在 DDL 过程中间的读写，但是对写入的数据量有上限，不能超过 innodb_online_alter_log_max_size（默认为 128M）。如果超过上限可能导致执行失败。 7、尽量设置字段为not null（1）聚合函数不准确 对于NULL值的列，使用聚合函数的时候会忽略NULL值。 （2）对于NULL值的列，是不能使用=表达式进行判断的，下面对name的查询是不成立的，必须使用is NULL。 （3）NULL和其他任何值进行运算都是NULL，包括表达式的值也是NULL。 user表第二条记录age是NULL，所以+1之后还是NULL，name是NULL，进行concat运算之后结果还是NULL。 （4）对于distinct和group by来说，所有的NULL值都会被视为相等，对于order by来说升序NULL会排在最前 （5）索引列存在NULL会导致优化器在做索引选择的时候更复杂，更加难以优化。~~（MySQL版本已优化） ## 8、MySQL in vs exists（版本优化已趋于接近，讨论无意义） - IN查询在内部表和外部表上都可以使用到索引；- Exists查询仅在内部表上可以使用到索引；- 当子查询结果集很大，而外部表较小的时候，Exists的Block Nested Loop(Block 嵌套循环)的作用开始显现，并弥补外部表无法用到索引的缺陷，查询效率会优于IN。- 当子查询结果集较小，而外部表很大的时候，Exists的Block嵌套循环优化效果不明显，IN 的外表索引优势占主要作用，此时IN的查询效率会优于Exists。 8、SQL优化总结到 SQL 优化中，就如下三点： 最大化利用索引。 尽可能避免全表扫描。 减少无效数据的查询。 参考资料1、https://javaguide.cn/high-performance/read-and-write-separation-and-library-subtable.html#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8 2、100亿数据平滑数据迁移,不影响服务：https://www.w3cschool.cn/architectroad/architectroad-data-smooth-migration.html 3、MySQL 5.7 特性：Online DDL：https://cloud.tencent.com/developer/article/1697076 4、为什么数据库字段要使用NOT NULL：https://cloud.tencent.com/developer/article/1812479","link":"/2023/09/25/database_optimize/"},{"title":"分布式锁","text":"","link":"/2023/09/25/distributed_clock/"},{"title":"分布式基础知识点","text":"分布式面试题 0、基本原则CAP指的是在一个分布式系统中： 一致性（Consistency） （等同于所有节点访问同一份最新的数据副本） 可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据） 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择） 这三个要素最多只能同时实现两点，不可能三者兼顾。 如果你的实际业务场景，更需要的是保证数据一致性。那么请使用CP类型的分布式锁，比如：zookeeper，它是基于磁盘的，性能可能没那么好，但数据一般不会丢。 如果你的实际业务场景，更需要的是保证数据高可用性。那么请使用AP类型的分布式锁，比如：redis，它是基于内存的，性能比较好，但有丢失数据的风险。 其实，在我们绝大多数分布式业务场景中，使用redis分布式锁就够了，真的别太较真。因为数据不一致问题，可以通过最终一致性方案解决。但如果系统不可用了，对用户来说是暴击一万点伤害。 一般来说，用Redis控制共享资源并且还要求数据安全要求较高的话，最终的保底方案是对业务数据做幂等控制，这样一来，即使出现多个客户端获得锁的情况也不会影响数据的一致性。 #1、分布式服务接口幂等性 其实保证幂等性（比如不能重复扣款）主要是三点： （1）对于每个请求必须有一个唯一的标识，举个例子：订单支付请求，肯定得包含订单ID，一个订单ID最多支付一次，对吧 （2）每次处理完请求之后，必须有一个记录标识这个请求处理过了，比如说常见得方案是再mysql中记录个状态啥得，比如支付之前记录一条这个订单得支付流水，而且支付流水采用order id作为唯一键（unique key）。只有成功插入这个支付流水，才可以执行实际得支付扣款 （3）每次接收请求需要进行判断之前是否处理过得逻辑处理，比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，order id已经存在了，唯一键约束生效，报错插入不进去得。然后你就不用再扣款了。 #2、zk的使用场景 （1）分布式协调：这个其实就是zk很经典的一个用法，简单来说，就好比，你系统A发送个请求到mq，然后B消费了之后处理。那A系统如何指导B系统的处理结果？用zk就可以实现分布式系统之间的协调工作。A系统发送请求之后可以在zk上对某个节点的值注册个监听器，一旦B系统处理完了就修改zk那个节点的值，A立马就可以收到通知，完美解决。 （2）分布所锁：对某一个数据联系发出两个修改操作，两台机器同时收到请求，但是只能一台机器先执行另外一个机器再执行，那么此时就可以使用zk分布式锁，一个机器接收到了请求之后先获取zk上的一把分布式锁，就是可以去创建一个znode，接着执行操作，然后另外一个机器也尝试去创建那个znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等等一个机器执行完了自己再执行。 zk分布式锁，其实做的比较简单，就是某个节点尝试创建临时znode（防止死锁呗），此时创建成功了就获取了这个锁，这个时候别的客户端来创建锁会失败，只能注册监听器来监听这个锁，释放锁就是删除这个znode，一旦释放掉就会反向通知客户端，然后等待着的客户端就可以再次尝试重新加锁。 （3）配置信息管理：zk可以用作很多系统的配置信息的管理，比如kafka，storm等等很多分布式系统都会选用zk来做一些元数据，配置信息的管理 （4）HA高可用性：这个应该是很常见的，比如hdfs，yarn等很多大数据系统，都选择基于zk来开发HA高可用机制，就是一个重要进程一般会主备两个，主进程挂了立马通过zk感知到切换到备份进程 3、分布式锁##（1）分布式锁特性 互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁； 高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署； 防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁； 独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁，别人给你解锁了； ##（2）分布式锁的缺陷 客户端长时间阻塞导致锁失效问题：客户端1得到了锁，因为网络问题或者GC等原因导致长时间阻塞，然后业务程序还没执行完锁就过期了，这时候客户端2也能正常拿到锁，可能会导致线程安全的问题。 redis服务器时钟漂移问题：如果redis服务器的机器时钟发生了向前跳跃，就会导致这个key过早超时失效，比如说客户端1拿到锁后，key的过期时间是12:02分，但redis服务器本身的时钟比客户端快了2分钟，导致key在12:00的时候就失效了，这时候，如果客户端1还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的问题。 单点实例安全问题：如果redis是单master模式的，当这台机宕机的时候，那么所有的客户端都获取不到锁了，为了提高可用性，可能就会给这个master加一个slave，但是因为redis的主从同步是异步进行的，可能会出现客户端1设置完锁后，master挂掉，slave提升为master，因为异步复制的特性，客户端1设置的锁丢失了，这时候客户端2设置锁也能够成功，导致客户端1和客户端2同时拥有锁。 （2）Redis中lua脚本保证操作原子性redis中使用lua脚本，可以保证操作的原子性，原因： 12“Atomicity of scriptsRedis uses the same Lua interpreter to run all the commands. Also Redis guarantees that a script is executed in an atomic way: no other script or Redis command will be executed while a script is being executed. This semantic is similar to the one of MULTI / EXEC. From the point of view of all the other clients the effects of a script are either still not visible or already completed.” （）Redis分布式锁说道Redis分布式锁大部分人都会想到：setnx+lua，或者知道set key value px milliseconds nx。后一种方式的核心实现命令如下： 123456789- 获取锁（unique_value可以是UUID等）SET resource_name unique_value NX PX 30000- 释放锁（lua脚本中，一定要比较value，防止误解锁）if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1])else return 0end 这种实现方式有3大要点（也是面试概率非常高的地方）： set命令要用set key value px milliseconds nx； value要具有唯一性； 释放锁时要验证value值，不能误解锁； 事实上这类琐最大的缺点就是它加锁时只作用在一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况： 在Redis的master节点上拿到了锁； 但是这个加锁的key还没有同步到slave节点； master故障，发生故障转移，slave节点升级为master节点； 导致锁丢失。 ##（）Redlock算法 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。 为了取到锁，客户端应该执行以下操作: 获取当前Unix时间，以毫秒为单位。 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。 ##（）Redis可重入锁 加锁主要是通过以下脚本实现的： 123456789101112if (redis.call('exists', KEYS[1]) == 0) then redis.call('hset', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end;if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end;return redis.call('pttl', KEYS[1]);1.2.3.4.5.6.7.8.9.10.11.12. 其中： KEYS[1]：锁名 ARGV[1]：过期时间 ARGV[2]：uuid + “:” + threadId，可认为是requestId 先判断如果锁名不存在，则加锁。 接下来，判断如果锁名和requestId值都存在，则使用hincrby命令给该锁名和requestId值计数，每次都加1。注意一下，这里就是重入锁的关键，锁重入一次值就加1。 如果锁名存在，但值不是requestId，则返回过期时间。 释放锁主要是通过以下脚本实现的： 123456789101112131415if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then return nilendlocal counter = redis.call('hincrby', KEYS[1], ARGV[3], -1);if (counter &gt; 0) then redis.call('pexpire', KEYS[1], ARGV[2]); return 0; else redis.call('del', KEYS[1]); redis.call('publish', KEYS[2], ARGV[1]); return 1; end; return nil1.2.3.4.5.6.7.8.9.10.11.12.13.14.15. 先判断如果锁名和requestId值不存在，则直接返回。 如果锁名和requestId值存在，则重入锁减1。 如果减1后，重入锁的value值还大于0，说明还有引用，则重试设置过期时间。 如果减1后，重入锁的value值还等于0，则可以删除锁，然后发消息通知等待线程抢锁。 （）读写锁与锁分段提升redis分布式锁性能 区分读写锁 将大锁分段：在java中ConcurrentHashMap，就是将数据分为16段，每一段都有单独的锁，并且处于不同锁段的数据互不干扰，以此来提升锁的性能 （）自动续期自动续期的功能是获取锁之后开启一个定时任务，每隔10秒判断一下锁是否存在，如果存在，则刷新过期时间。如果续期3次，也就是30秒之后，业务方法还是没有执行完，就不再续期了。 在实现自动续期功能时，还需要设置一个总的过期时间，可以跟redisson保持一致，设置成30秒。如果业务代码到了这个总的过期时间，还没有执行完，就不再自动续期了。 ##（）Redis分布式锁与ZK比较 redis分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能 zk分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较低 另外一点就是，如果redis获取锁的那个客户端bug了，或者挂了，那么等待超时时间之后才能释放锁，而zk的话，因为创建的是临时节点，只要客户端挂了，znode就没了，此时就会自动释放锁 （）乐观锁和悲观锁乐观锁可以使用CAS和版本号机制来实施 （1）CAS（Compare And Swap）：CAS操作包括了3个操作数： 需要读写的内存位置(V) 进行比较的预期值(A) 拟写入的新值(B) （2）版本号机制 除了CAS，版本号机制也可以用来实现乐观锁。版本号机制的基本思路是在数据中增加一个字段version，表示该数据的版本号，每当数据被修改，版本号加1。当某个线程查询数据时，将该数据的版本号一起查出来；当该线程更新数据时，判断当前版本号与之前读取的版本号是否一致，如果一致才进行操作。 乐观锁和悲观锁比较： 1、功能限制与悲观锁相比，乐观锁适用的场景受到了更多的限制，无论是CAS还是版本号机制。 例如，CAS只能保证单个变量操作的原子性，当涉及到多个变量时，CAS是无能为力的，而synchronized则可以通过对整个代码块加锁来处理。再比如版本号机制，如果query的时候是针对表1，而update的时候是针对表2，也很难通过简单的版本号来实现乐观锁。 2、竞争激烈程度如果悲观锁和乐观锁都可以使用，那么选择就要考虑竞争的激烈程度： 当竞争不激烈 (出现并发冲突的概率小)时，乐观锁更有优势，因为悲观锁会锁住代码块或数据，其他线程无法同时访问，影响并发，而且加锁和释放锁都需要消耗额外的资源。当竞争激烈(出现并发冲突的概率大)时，悲观锁更有优势，因为乐观锁在执行更新时频繁失败，需要不断重试，浪费CPU资源。 乐观锁加锁吗？ （1）乐观锁本身是不加锁的，只是在更新时判断一下数据是否被其他线程更新了；AtomicInteger便是一个例子。 （2）有时乐观锁可能与加锁操作合作，例如，在前述updateCoins()的例子中，MySQL在执行update时会加排它锁。但这只是乐观锁与加锁操作合作的例子，不能改变“乐观锁本身不加锁”这一事实。 4、分布式事务5、分布式一致性算法Raft #参考文档 （1）分布式锁：https://juejin.cn/post/6996915693811662884 （2）乐观锁和悲观锁：https://www.cnblogs.com/kismetv/p/10787228.html","link":"/2023/09/25/distributed_base/"},{"title":"分布式缓存","text":"缓存的应用场景 高频访问的数据：限于磁盘 I/O 的瓶颈，对于高频访问的数据，需要缓存起来提高性能，降低下游数据库的压力冲击； 复杂运算的结果：对于需要耗费 CPU、经过复杂运算才能获得的结果，需要缓存来，做到“一劳长时间逸”，如 count(id)统计论坛在线人数； 读多写少：每次读都需要 select 甚至 join 很多表，数据库压力大，由于写得少，容易做到数据的一致性，非常适合缓存的应用； 一致性要求低：由于缓存的数据来源于数据库，在高并发时数据不一致性就比较凸显，不一致的问题可以解决但代价不菲； 缓存常见问题1、缓存雪崩 Cache Avalanche缓存雪崩是指当大量缓存同时过期或缓存服务宕机，所有请求的都直接访问数据库，造成数据库高负载，影响性能，甚至数据库宕机，它和缓存击穿的区别在于失效 key 的数量。 解决措施 集群 随机过期时间 服务降级或熔断 2、缓存穿透 Cache Penetration缓存穿透是指数据库中没有符合条件的数据，缓存服务器中也就没有缓存数据，导致业务系统每次都绕过缓存服务器查询下游的数据库，缓存服务器完全失去了其应用的作用。如果黑客试图发起针对该 key 的大量访问攻击，数据库将不堪重负，最终可能导致崩溃宕机。 解决措施： #####参数校验 存储空值/默认值 布隆过滤器(Bloom Filter) 3、缓存击穿 Cache Breakdown缓存击穿是指当某一 key 的缓存过期时大并发量的请求同时访问此 key，瞬间击穿缓存服务器直接访问数据库，让数据库处于负载的情况，缓存击穿一般发生在高并发的互联网应用场景。 解决措施： 锁更新 异步更新（例如热点数据永远不过期） Redis1、Redis介绍Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache, and message broker. ——From https://redis.io/ 优势： 支持多种数据类型 持久化存储 读写性能很好，可以达到10w/s的频率 原子操作，事务 …… 2、Redis数据结构（1）string(字符串) 动态字符串，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 ArrayList。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051SET/GET：设置/查询&gt; SET key valueOK&gt; GET key&quot;value&quot;&gt; EXISTS key(integer) 1&gt; DEL key(integer) 1&gt; GET key(nil)MSET/MGET：批量设置/查询&gt; MSET key1 value1 key2 value2OK&gt; MGET key1 key21) &quot;value1&quot;2) &quot;value2&quot;expire：设置过期时间&gt; expire key 5(integer) 1&gt; get key&quot;value&quot;&gt; get key(nil)SETEX = SET + EXPIRE&gt; setex key 5 valueOK&gt; get key&quot;value&quot;&gt; get key(nil)getset：为 key 设置一个值并返回原值&gt; set key valueOK&gt; getset key value1&quot;value&quot;&gt; get key&quot;value1&quot;incr：原子性的自增操作incrby：加法&gt; set key 10OK&gt; incr key(integer) 11&gt; incrby key 5(integer) 16 （2）list(列表) Redis 的列表相当于 Java 语言中的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。 12345678910111213141516LPUSH 和 RPUSH 分别可以向 list 的左边（头部）和右边（尾部）添加一个新元素；LRANGE 命令可以从 list 中取出一定范围的元素；LINDEX 命令可以从 list 中取出指定下表的元素，相当于 Java 链表操作中的 get(int index) 操作；&gt; rpush list 1(integer) 1&gt; rpush list 2(integer) 2&gt; lpush list 10(integer) 3&gt; lrange list 0 -1 # -1 表示倒数第一个元素, 这里表示从第一个元素到最后一个元素，即所有1) &quot;10&quot;2) &quot;1&quot;3) &quot;2&quot;&gt; lindex list 0&quot;10&quot; （3）hash(字典) Redis 中的字典相当于 Java 中的 HashMap，内部实现也差不多类似，都是通过 “数组 + 链表” 的链地址法来解决部分 哈希冲突 渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务以及 hash 操作指令中，循序渐进的把旧字典的内容迁移到新字典中。当搬迁完成了，就会使用新的 hash 结构取而代之。 渐进式rehash 扩缩容 （4）set(集合) （5）zset(有序集合) 3、Redis","link":"/2023/09/27/distributed_cache/"},{"title":"算法基础","text":"","link":"/2023/09/25/algorithm_base/"},{"title":"分布式ID","text":"","link":"/2023/09/25/distributed_id/"},{"title":"分布式配置中心","text":"","link":"/2023/09/25/distributed_config/"},{"title":"Java基础知识点","text":"Java学习 1、Java 虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM 并不是只有一种！只要满足 JVM 规范，每个公司、组织或者个人都可以开发自己的专属 JVM。 JDK 是 Java Development Kit 缩写，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。 JRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。 2、在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。 1我们需要格外注意的是 .class-&gt;机器码 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT（just-in-time compilation） 编译器，而 JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言 。 3、静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。 4、可变参数只能作为函数的最后一个参数，但其前面可以有也可以没有任何其他参数。 5、基本类型和包装类型的区别？ 包装类型不赋值就是 null ，而基本类型有默认值且不是 null。 包装类型可用于泛型，而基本类型不可以。 基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 static 修饰 ）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。 相比于对象类型， 基本数据类型占用的空间非常小。 为什么说是几乎所有对象实例呢？ 这是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存 6、两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。 7、什么是自动拆装箱？ 装箱：将基本类型用它们对应的引用类型包装起来； 拆箱：将包装类型转换为基本数据类型； 8、new 运算符，new 创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。 9、面向对象三大特征 封装 封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。就好像我们看不到挂在墙上的空调的内部的零件信息（也就是属性），但是可以通过遥控器（方法）来控制空调。如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。就好像如果没有空调遥控器，那么我们就无法操控空凋制冷，空调本身就没有意义了（当然现在还有很多其他方法 ，这里只是为了举例子）。 继承 不同类型的对象，相互之间经常有一定数量的共同点。例如，小明同学、小红同学、小李同学，都共享学生的特性（班级、学号等）。同时，每一个对象还定义了额外的特性使得他们与众不同。例如小明的数学比较好，小红的性格惹人喜爱；小李的力气比较大。继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承，可以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。 关于继承如下 3 点请记住： 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。（以后介绍）。 多态 多态，顾名思义，表示一个对象具有多种的状态，具体表现为父类的引用指向子类的实例。 多态的特点: 对象类型和引用类型之间具有继承（类）/实现（接口）的关系； 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在程序运行期间才能确定； 多态不能调用“只在子类存在但在父类不存在”的方法； 如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法。 10、接口和抽象类有什么共同点和区别？ 共同点 ： 都不能被实例化。 都可以包含抽象方法。 都可以有默认实现的方法（Java 8 可以用 default 关键在接口中定义默认方法）。 区别 ： 接口主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系（比如说我们抽象了一个发送短信的抽象类，）。 一个类只能继承一个类，但是可以实现多个接口。 接口中的成员变量只能是 public static final 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值。 区别可参考：https://tobebetterjavaer.com/oo/interface.html#_04%E3%80%81%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%8C%BA%E5%88%AB 1）语法层面上 抽象类可以提供成员方法的实现细节，而接口中只能存在 public abstract 方法； 抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是 public static final 类型的； 接口中不能含有静态代码块，而抽象类可以有静态代码块； 一个类只能继承一个抽象类，而一个类却可以实现多个接口。 2）设计层面上 抽象类是对一种事物的抽象，即对类抽象，继承抽象类的子类和抽象类本身是一种 is-a 的关系。而接口是对行为的抽象。抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类局部（行为）进行抽象。 举个简单的例子，飞机和鸟是不同类的事物，但是它们都有一个共性，就是都会飞。那么在设计的时候，可以将飞机设计为一个类 Airplane，将鸟设计为一个类 Bird，但是不能将 飞行 这个特性也设计为类，因此它只是一个行为特性，并不是对一类事物的抽象描述。 此时可以将 飞行 设计为一个接口 Fly，包含方法 fly()，然后 Airplane 和 Bird 分别根据自己的需要实现 Fly 这个接口。然后至于有不同种类的飞机，比如战斗机、民用飞机等直接继承 Airplane 即可，对于鸟也是类似的，不同种类的鸟直接继承 Bird 类即可。从这里可以看出，继承是一个 “是不是”的关系，而 接口 实现则是 “有没有”的关系。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系，比如鸟是否能飞（或者是否具备飞行这个特点），能飞行则可以实现这个接口，不能飞行就不实现这个接口。 接口是对类的某种行为的一种抽象，接口和类之间并没有很强的关联关系，举个例子来说，所有的类都可以实现 Serializable 接口)，从而具有序列化的功能，但不能说所有的类和 Serializable 之间是 is-a 的关系。 抽象类作为很多子类的父类，它是一种模板式设计。而接口是一种行为规范，它是一种辐射式设计。什么是模板式设计？最简单例子，大家都用过 ppt 里面的模板，如果用模板 A 设计了 ppt B 和 ppt C，ppt B 和 ppt C 公共的部分就是模板 A 了，如果它们的公共部分需要改动，则只需要改动模板 A 就可以了，不需要重新对 ppt B 和 ppt C 进行改动。而辐射式设计，比如某个电梯都装了某种报警器，一旦要更新报警器，就必须全部更新。也就是说对于抽象类，如果需要添加新的方法，可以直接在抽象类中添加具体的实现，子类可以不进行变更；而对于接口则不行，如果接口进行了变更，则所有实现这个接口的类都必须进行相应的改动。 11、== 和 equals 区别 == 是 Java 中一种操作符，它有两种比较方式： 对于基本数据类型来说， == 判断的是两边的值是否相等 对于引用类型来说， == 判断的是两边的引用是否相等，也就是判断两个对象是否指向了同一块内存区域 equals 是 Java 中所有对象的父类，即 Object 类定义的一个方法。它只能比较对象，它表示的是引用双方的值是否相等。 所以记住，并不是说 == 比较的就是引用是否相等，equals 比较的就是值，这需要区分来说的。 12、在 JDK1.7 及以后会判断运行时常量池中是否有指定的字符串，如果没有的话，就把字符串添加到常量池中，并返回常量池中的对象。 12345678910private void StringOverrideEquals(){ String s1 = &quot;aaa&quot;; String s2 = &quot;aa&quot; + new String(&quot;a&quot;); String s3 = new String(&quot;aaa&quot;); System.out.println(s1.intern().equals(s1)); //true，因为 s1 字符串创建出来就已经在常量池中存在了 System.out.println(s1.intern().equals(s2)); //false，因为 s1 返回的是常量池中的对象，而 s2 返回的是堆中的对象 System.out.println(s3.intern().equals(s1)); //true ，因为 s3 对象虽然在堆中创建了一个对象，但是 s3 中的 &quot;aaa&quot; 返回的是常量池中的对象} 13、基本类型和包装类型的区别 用途：除了定义一些常量和局部变量之外，我们在其他地方比如方法参数、对象属性中很少会使用基本类型来定义变量。并且，包装类型可用于泛型，而基本类型不可以。 存储方式：基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 static 修饰 ）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。 占用空间：相比于包装类型（对象类型）， 基本数据类型占用的空间往往非常小。 默认值：成员变量包装类型不赋值就是 null ，而基本类型有默认值且不是 null。 比较方式：对于基本数据类型来说，== 比较的是值。对于包装数据类型来说，== 比较的是对象的内存地址。所有整型包装类对象之间值的比较，全部使用 equals() 方法。 为什么说是几乎所有对象实例都存在于堆中呢？ 这是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存 ⚠️ 注意：基本数据类型存放在栈中是一个常见的误区！ 基本数据类型的成员变量如果没有被 static 修饰的话（不建议这么使用，应该要使用基本数据类型对应的包装类型），就存放在堆中。 123class BasicTypeVar{ private int x;} 14、包装类型的缓存机制 Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。 Byte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True or False。 15、String、StringBuilder、StringBuffer 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 对于三者使用的总结： 操作少量的数据: 适用 String 单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer 16、 transient 关键字 transient 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。 关于 transient 还有几点注意： transient 只能修饰变量，不能修饰类和方法。 transient 修饰的变量，在反序列化后变量值将会被置成类型的默认值。例如，如果是修饰 int 类型，那么反序列后结果就是 0。 static 变量因为不属于任何对象(Object)，所以无论有没有 transient 关键字修饰，均不会被序列化。 17、final保证可见性的前提是未发生this引用逃逸，参考：https://zhuanlan.zhihu.com/p/477481115 18、java命令的参数，传入的是main函数所在的类的名字，而不是class文件；java会根据类名自动去找class文件。 增加了package名，所以class名也变了，行不改名坐不改姓，自然要带上姓（即所谓全限定名）。 Java 会根据包名对应出目录结构，并从class path搜索该目录去找class文件。由于默认的class path是当前目录， 参考资料（1）https://javaguide.cn/java/basis/java-basic-questions-01.html","link":"/2023/09/25/java_base/"},{"title":"消息队列","text":"","link":"/2023/09/25/distributed_message_queue/"},{"title":"Redis","text":"","link":"/2023/09/25/distributed_redis/"},{"title":"分布式事务","text":"","link":"/2023/09/25/distributed_transaction/"},{"title":"Java并发","text":"Java并发面试题 原子性：是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。 可见性：是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：即程序执行的顺序按照代码的先后顺序执行。 内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障 死锁的发生必须具备以下四个必要条件： 互斥条件 请求和保持条件 不剥夺条件 环路等待条件 1、volatile 可见性：被volatile修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新 有序性：volatile可以禁止指令重排，这就保证了代码的程序会严格按照代码的先后顺序执行 注意：volatile不能保证原子性。 2、同步方法与同步代码块对于同步方法，JVM采用ACC_SYNCHRONIZED标记符来实现同步。 对于同步代码块。JVM采用monitorenter、monitorexit两个指令来实现同步。 Method-level synchronization is performed implicitly, as part of method invocation and return. A synchronized method is distinguished in the run-time constant pool’s method_info structure by the ACC_SYNCHRONIZED flag, which is checked by the method invocation instructions. When invoking a method for which ACC_SYNCHRONIZED is set, the executing thread enters a monitor, invokes the method itself, and exits the monitor whether the method invocation completes normally or abruptly. During the time the executing thread owns the monitor, no other thread may enter it. If an exception is thrown during invocation of the synchronized method and the synchronized method does not handle the exception, the monitor for the method is automatically exited before the exception is rethrown out of the synchronized method. 主要说的是： 方法级的同步是隐式的。同步方法的常量池中会有一个ACC_SYNCHRONIZED标志。当某个线程要访问某个方法的时候，会检查是否有ACC_SYNCHRONIZED，如果有设置，则需要先获得监视器锁，然后开始执行方法，方法执行之后再释放监视器锁。这时如果其他线程来请求执行方法，会因为无法获得监视器锁而被阻断住。值得注意的是，如果在方法执行过程中，发生了异常，并且方法内部并没有处理该异常，那么在异常被抛到方法外面之前监视器锁会被自动释放。 3、synchronized（1）synchronized是Java提供的一个并发控制的关键字。主要有两种用法，分别是同步方法和同步代码块。也就是说，synchronized既可以修饰方法也可以修饰代码块。被synchronized修饰的代码块及方法，在同一时间，只能被单个线程访问。 原子性：线程1在执行monitorenter指令的时候，会对Monitor进行加锁，加锁后其他线程无法获得锁，除非线程1主动解锁。即使在执行过程中，由于某种原因，比如CPU时间片用完，线程1放弃了CPU，但是，他并没有进行解锁。而由于synchronized的锁是可重入的，下一个时间片还是只能被他自己获取到，还是会继续执行代码。直到所有代码执行完。这就保证了原子性 可见性：被synchronized修饰的代码，在开始执行时会加锁，执行完成后会进行解锁。而为了保证可见性，有一条规则是这样的：对一个变量解锁之前，必须先把此变量同步回主存中。这样解锁后，后续线程就可以访问到被修改后的值。所以，synchronized关键字锁住的对象，其值是具有可见性的 有序性：synchronized是无法禁止指令重排和处理器优化的，但由于as-if-serial语义的限制，被synchronized修饰的代码，同一时间只能被同一线程访问。那么也就是单线程执行的。所以，可以保证其有序性 as-if-serial语义：保证了单线程中，指令重排是有一定的限制的，而只要编译器和处理器都遵守了这个语义，那么就可以认为单线程程序是按照顺序执行的。当然，实际上还是有重排的，只不过我们无须关心这种重排的干扰 总结： synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁； synchronized 关键字加到实例方法上是给对象实例上锁； 尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能。 4、 Thread 类的 run、start区别new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结：调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。 5、sleep() 方法和 wait() 方法对比共同点：两者都可以暂停线程的执行。 区别： sleep() 方法没有释放锁，而 wait() 方法释放了锁 。 wait() 通常被用于线程间交互/通信，sleep()通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。sleep()方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 sleep() 是 Thread 类的静态本地方法，wait() 则是 Object 类的本地方法。为什么这样设计呢？wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）。类似的问题：为什么 sleep() 方法定义在 Thread 中？因为 sleep() 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。 #6、锁优化 （1）适应性自旋锁 自旋锁和阻塞锁最大的区别就是，到底要不要放弃处理器的执行时间。对于阻塞锁和自旋锁来说，都是要等待获得共享资源。但是阻塞锁是放弃了CPU时间，进入了等待区，等待被唤醒。而自旋锁是一直“自旋”在那里，时刻的检查共享资源是否可以被访问。 由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用CPU时间。如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁 （2）锁消除 在动态编译同步块的时候，JIT编译器可以借助一种被称为逃逸分析（Escape Analysis）的技术来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。 如果同步块所使用的锁对象通过这种分析被证实只能够被一个线程访问，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步。 （3）锁粗化 如果在一段代码中连续的对同一个对象反复加锁解锁，其实是相对耗费资源的，这种情况可以适当放宽加锁的范围，减少性能消耗。 当JIT发现一系列连续的操作都对同一个对象反复加锁和解锁，甚至加锁操作出现在循环体中的时候，会将加锁同步的范围扩散（粗化）到整个操作序列的外部。 参考资料（1）https://javaguide.cn/java/concurrent/java-concurrent-questions-01.html 遗留问题： （1）构造方法为什么是线程安全的？","link":"/2023/09/25/java_concurrent/"},{"title":"Zookeeper","text":"","link":"/2023/09/25/distributed_zookeeper/"},{"title":"Gradle","text":"","link":"/2023/09/25/java_gradle/"},{"title":"JVM","text":"","link":"/2023/09/25/java_jvm/"},{"title":"Mybatis","text":"","link":"/2023/09/25/java_mybatis/"},{"title":"Spring &amp; SpringBoot","text":"SpringBoot学习 1、IoCIoC（Inversion of Control:控制反转） 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。不过， IoC 并非 Spring 特有，在其他语言中也有应用。 为什么叫控制反转？ 控制：指的是对象创建（实例化、管理）的权力 反转：控制权交给外部环境（Spring 框架、IoC 容器） ##2、将一个类声明为 Bean 的注解 @Component：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。 3、@Component 和 @Bean 的区别 @Component 注解作用于类，而@Bean注解作用于方法。 @Component通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。 @Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。 ##4、@Autowired 和 @Resource 的区别是什么？ @Autowired 是 Spring 提供的注解，@Resource 是 JDK 提供的注解。 Autowired 默认的注入方式为byType（根据类型进行匹配），@Resource默认注入方式为 byName（根据名称进行匹配）。 当一个接口存在多个实现类的情况下，@Autowired 和@Resource都需要通过名称才能正确匹配到对应的 Bean。Autowired 可以通过 @Qualifier 注解来显式指定名称，@Resource可以通过 name 属性来显式指定名称。 @Autowired 支持在构造函数、方法、字段和参数上使用。@Resource 主要用于字段和方法上的注入，不支持在构造函数或参数上使用。 5、AOPAOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy（底层通过反射实现）或者CGLIB的动态代理（底层通过继承实现），去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理。 6、Spring AOP 和 AspectJ AOP 区别Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单， 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。 7、自动装配@SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合。根据 SpringBoot 官网，这三个注解的作用分别是： @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制。通过 SpringFactoriesLoader 最终加载META-INF/spring.factories中的自动配置类实现自动装配，自动配置类其实就是通过@Conditional按需加载的配置类，想要其生效必须引入spring-boot-starter-xxx包实现起步依赖 @Configuration：允许在上下文中注册额外的 bean 或导入其他配置类 @ComponentScan：扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除TypeExcludeFilter和AutoConfigurationExcludeFilter。 ##8、Spring 框架中用到的设计模式 工厂设计模式 : Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 …… 参考资料1、https://javaguide.cn/system-design/framework/spring/spring-knowledge-and-questions-summary.html todo： （1）cglib实现原理？","link":"/2023/09/25/java_springboot/"},{"title":"Docker","text":"","link":"/2023/09/25/k8s_docker/"},{"title":"Java线程池","text":"1. 线程池介绍顾名思义，线程池就是管理一系列线程的资源池，其提供了一种限制和管理线程资源的方式。每个线程池还维护一些基本统计信息，例如已完成任务的数量。 这里借用《Java 并发编程的艺术》书中的部分内容来总结一下使用线程池的好处： 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 线程池一般用于执行多个不相关联的耗时任务，没有多线程的情况下，任务顺序执行，使用了线程池的话可让多个不相关联的任务同时执行。 2. Java Executor框架Executor 框架是 Java5 之后引进的，在 Java 5 之后，通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题。 this 逃逸是指在构造函数返回之前其他线程就持有该对象的引用，调用尚未构造完全的对象的方法可能引发令人疑惑的错误。可参考：https://zhuanlan.zhihu.com/p/477481115 Executor 框架结构主要由三大部分组成： 任务(Runnable/Callable)：执行任务需要实现的 Runnable 接口 或 Callable接口。 任务的执行(Executor) 异步计算的结果(Future) 3. ThreadPoolExecutor 主要参数 corePoolSize: 任务队列未达到队列容量时，最大可以同时运行的线程数量。 maximumPoolSize: 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数 : keepAliveTime:线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁。 unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。 4. 饱和策略如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy：此策略将丢弃最早的未处理的任务请求。 5. 线程池创建方式（1）通过ThreadPoolExecutor构造函数来创建（推荐） （2）通过 Executor 框架的工具类 Executors 来创建。 我们可以创建多种类型的 ThreadPoolExecutor： FixedThreadPool：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 SingleThreadExecutor： 该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 ScheduledThreadPool：该返回一个用来在给定的延迟后运行任务或者定期执行任务的线程池。 注：《阿里巴巴 Java 开发手册》强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 构造函数的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险（Executors创建的线程池，队列长度为Interger.MAX_VALUE，可能堆积大量的请求，导致 OOM）。 6. 阻塞队列不同的线程池会选用不同的阻塞队列，我们可以结合内置线程池来分析。 容量为 Integer.MAX_VALUE 的 LinkedBlockingQueue（无界队列）：FixedThreadPool 和 SingleThreadExector 。由于队列永远不会被放满，因此FixedThreadPool最多只能创建核心线程数的线程。 SynchronousQueue（同步队列）：CachedThreadPool 。SynchronousQueue 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，CachedThreadPool 的最大线程数是 Integer.MAX_VALUE ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。 DelayedWorkQueue（延迟阻塞队列）：ScheduledThreadPool 和 SingleThreadScheduledExecutor 。DelayedWorkQueue 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。DelayedWorkQueue 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 Integer.MAX_VALUE，所以最多只能创建核心线程数的线程。 7. Runnable vs CallableRunnable自 Java 1.0 以来一直存在，但Callable仅在 Java 1.5 中引入,目的就是为了来处理Runnable不支持的用例。Runnable 接口不会返回结果或抛出检查异常，但是 Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。 8. execute() vs submit() execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法的话，如果在 timeout 时间内任务还没有执行完，就会抛出 java.util.concurrent.TimeoutException。 9. shutdown() vs shutdownNow() shutdown（） :关闭线程池，线程池的状态变为 SHUTDOWN。线程池不再接受新任务了，但是队列里的任务得执行完毕。 shutdownNow（） :关闭线程池，线程池的状态变为 STOP。线程池会终止当前正在运行的任务，并停止处理排队的任务并返回正在等待执行的 List。 10. isTerminated() vs isShutdown() isShutDown 当调用 shutdown() 方法后返回为 true。 isTerminated 当调用 shutdown() 方法后，并且所有提交的任务完成后返回为 true 11. 线程池和 ThreadLocal线程池和 ThreadLocal共用，可能会导致线程从ThreadLocal获取到的是旧值/脏数据。这是因为线程池会复用线程对象，与线程对象绑定的类的静态属性 ThreadLocal 变量也会被重用，这就导致一个线程可能获取到其他线程的ThreadLocal 值。 可考虑使用TransmittableThreadLocal， 项目地址：https://github.com/alibaba/transmittable-thread-local 。 参考文档（1）https://javaguide.cn/java/concurrent/java-thread-pool-summary.html","link":"/2023/09/25/java_threadpool/"},{"title":"k8s监控","text":"","link":"/2023/09/25/k8s_monitor/"},{"title":"网络基础知识点","text":"","link":"/2023/09/25/network_base/"},{"title":"Java版本新特性","text":"","link":"/2023/09/25/java_new_feature/"},{"title":"Java IO","text":"","link":"/2023/09/25/java_io/"},{"title":"Maven","text":"Maven学习 1、介绍对于开发者来说，Maven 的主要作用主要有 3 个： 项目构建：提供标准的、跨平台的自动化项目构建方式。 依赖管理：方便快捷的管理项目依赖的资源（jar 包），避免资源间的版本冲突问题。 统一开发结构：提供标准的、统一的项目结构。 2、Maven 的依赖范围 compile：编译依赖范围（默认），使用此依赖范围对于编译、测试、运行三种都有效，即在编译、测试和运行的时候都要使用该依赖 Jar 包。 test：测试依赖范围，从字面意思就可以知道此依赖范围只能用于测试，而在编译和运行项目时无法使用此类依赖，典型的是 JUnit，它只用于编译测试代码和运行测试代码的时候才需要。 provided：此依赖范围，对于编译和测试有效，而对运行时无效。比如 servlet-api.jar 在 Tomcat 中已经提供了，我们只需要的是编译期提供而已。 runtime：运行时依赖范围，对于测试和运行有效，但是在编译主代码时无效，典型的就是 JDBC 驱动实现。 system：系统依赖范围，使用 system 范围的依赖时必须通过 systemPath 元素显示地指定依赖文件的路径，不依赖 Maven 仓库解析，所以可能会造成建构的不可移植。 3、Maven 依赖调解Maven 在遇到这种问题的时候，会遵循 路径最短优先 和 声明顺序优先 两大原则。 4、Maven生命周期Maven 定义了 3 个生命周期META-INF/plexus/components.xml： default 生命周期 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;phases&gt; &lt;!-- 验证项目是否正确，并且所有必要的信息可用于完成构建过程 --&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;!-- 建立初始化状态，例如设置属性 --&gt; &lt;phase&gt;initialize&lt;/phase&gt; &lt;!-- 生成要包含在编译阶段的源代码 --&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;!-- 处理源代码 --&gt; &lt;phase&gt;process-sources&lt;/phase&gt; &lt;!-- 生成要包含在包中的资源 --&gt; &lt;phase&gt;generate-resources&lt;/phase&gt; &lt;!-- 将资源复制并处理到目标目录中，为打包阶段做好准备。 --&gt; &lt;phase&gt;process-resources&lt;/phase&gt; &lt;!-- 编译项目的源代码 --&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;!-- 对编译生成的文件进行后处理，例如对 Java 类进行字节码增强/优化 --&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;!-- 生成要包含在编译阶段的任何测试源代码 --&gt; &lt;phase&gt;generate-test-sources&lt;/phase&gt; &lt;!-- 处理测试源代码 --&gt; &lt;phase&gt;process-test-sources&lt;/phase&gt; &lt;!-- 生成要包含在编译阶段的测试源代码 --&gt; &lt;phase&gt;generate-test-resources&lt;/phase&gt; &lt;!-- 处理从测试代码文件编译生成的文件 --&gt; &lt;phase&gt;process-test-resources&lt;/phase&gt; &lt;!-- 编译测试源代码 --&gt; &lt;phase&gt;test-compile&lt;/phase&gt; &lt;!-- 处理从测试代码文件编译生成的文件 --&gt; &lt;phase&gt;process-test-classes&lt;/phase&gt; &lt;!-- 使用合适的单元测试框架（Junit 就是其中之一）运行测试 --&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;!-- 在实际打包之前，执行任何的必要的操作为打包做准备 --&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;!-- 获取已编译的代码并将其打包成可分发的格式，例如 JAR、WAR 或 EAR 文件 --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- 在执行集成测试之前执行所需的操作。 例如，设置所需的环境 --&gt; &lt;phase&gt;pre-integration-test&lt;/phase&gt; &lt;!-- 处理并在必要时部署软件包到集成测试可以运行的环境 --&gt; &lt;phase&gt;integration-test&lt;/phase&gt; &lt;!-- 执行集成测试后执行所需的操作。 例如，清理环境 --&gt; &lt;phase&gt;post-integration-test&lt;/phase&gt; &lt;!-- 运行任何检查以验证打的包是否有效并符合质量标准。 --&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;!-- 将包安装到本地仓库中，可以作为本地其他项目的依赖 --&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;!-- 将最终的项目包复制到远程仓库中与其他开发者和项目共享 --&gt; &lt;phase&gt;deploy&lt;/phase&gt;&lt;/phases&gt; clean生命周期 site生命周期 todo： （1）provided依赖的包是否会打入最后的jar包？理论上不会，但是使用spring-boot-maven-plugin为了保证jar包能独立运行，最终仍会打包进去，有待验证。 （2）Gradle学习？","link":"/2023/09/25/java_maven/"}],"tags":[{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"todo","slug":"todo","link":"/tags/todo/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"缓存","slug":"缓存","link":"/tags/%E7%BC%93%E5%AD%98/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"监控","slug":"监控","link":"/tags/%E7%9B%91%E6%8E%A7/"},{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"}],"categories":[{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"k8s","slug":"k8s","link":"/categories/k8s/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"}],"pages":[{"title":"About me","text":"一枚小码农","link":"/about/index.html"}]}